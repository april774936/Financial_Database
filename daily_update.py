import os, json, gspread, time
import yfinance as yf
import pandas as pd
from datetime import datetime, timedelta
from oauth2client.service_account import ServiceAccountCredentials
from fredapi import Fred

def daily_professional_update():
    # 1. ì´ˆê¸° ì„¤ì • ë° API ì—°ê²°
    scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
    creds_json = json.loads(os.environ.get('GSPREAD_JSON'))
    creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_json, scope)
    client = gspread.authorize(creds)
    fred = Fred(api_key=os.environ.get('FRED_API_KEY'))
    
    sheets_info = {'ASSETS': os.environ.get('SHEET_ID_ASSETS'), 
                   'LIQUID': os.environ.get('SHEET_ID_LIQUID'), 
                   'MACRO': os.environ.get('SHEET_ID_MACRO')}

    # ë°ì´í„° ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•´ ì¡°íšŒ ê¸°ê°„ì„ 2ë…„ìœ¼ë¡œ í™•ëŒ€ (Backfill ë¡œì§)
    start_date = (datetime.now() - timedelta(days=730)).strftime('%Y-%m-%d')
    today_str = datetime.now().strftime('%Y-%m-%d')

    # 2. ê³ ì •ë°€ í‹°ì»¤ ë§¤í•‘ (ê°€ì¥ ì—…ë°ì´íŠ¸ê°€ ë¹ ë¥¸ ì†ŒìŠ¤ë¡œ êµì²´)
    yf_map = {
        'BTC-USD': ['ASSETS', 'Crypto', 'ë¹„íŠ¸ì½”ì¸'],
        'ETH-USD': ['ASSETS', 'Crypto', 'ì´ë”ë¦¬ì›€'], # 2024ë…„ ë©ˆì¶¤ í•´ê²°
        'GC=F': ['ASSETS', 'Commodity', 'ê³¨ë“œ(ê¸ˆ)'],
        'SI=F': ['ASSETS', 'Commodity', 'ì‹¤ë²„(ì€)'],
        'HG=F': ['ASSETS', 'Commodity', 'êµ¬ë¦¬_í˜„ë¬¼'], # 2024ë…„ ë©ˆì¶¤ í•´ê²°
        'CL=F': ['ASSETS', 'Energy', 'WTIì›ìœ '],
        '^NDX': ['ASSETS', 'Index', 'ë‚˜ìŠ¤ë‹¥100'],
        '^GSPC': ['ASSETS', 'Index', 'S&P500'],
        '^DJI': ['ASSETS', 'Index', 'ë‹¤ìš°ì¡´ìŠ¤30'],
        'DX-Y.NYB': ['MACRO', 'Currency', 'ë‹¬ëŸ¬ì¸ë±ìŠ¤'] # FRED ëŒ€ì‹  yfinanceì—ì„œ ì‹¤ì‹œê°„ ìˆ˜ì§‘
    }

    fred_map = {
        # ìœ ë™ì„±/ì •ì±…
        'DFEDTARU': ['LIQUID', 'Policy', 'ê¸°ì¤€ê¸ˆë¦¬(ìƒë‹¨)', 1],
        'WALCL': ['LIQUID', 'Liquidity', 'ì—°ì¤€ì´ìì‚°', 1000000],
        'WTREGEN': ['LIQUID', 'Liquidity', 'TGAì”ê³ ', 1],
        'RRPONTSYD': ['LIQUID', 'Liquidity', 'ì—­ë ˆí¬ì”ê³ ', 1],
        'T10Y2Y': ['LIQUID', 'Rates', 'ì¥ë‹¨ê¸°ê¸ˆë¦¬ì°¨', 1],
        'DGS10': ['LIQUID', 'Rates', 'ë¯¸_10ë…„ë¬¼_ê¸ˆë¦¬', 1],
        'DGS2': ['LIQUID', 'Rates', 'ë¯¸_2ë…„ë¬¼_ê¸ˆë¦¬', 1],
        'BAMLH0A0HYM2': ['LIQUID', 'Rates', 'ì •í¬ë³¸ë“œìŠ¤í”„ë ˆë“œ', 1], # ì‹ ìš© ì§€í‘œ ì—…ë°ì´íŠ¸
        'VIXCLS': ['LIQUID', 'Volatility', 'VIXê³µí¬ì§€ìˆ˜', 1],
        'BUSLOANS': ['LIQUID', 'Economy', 'ì€í–‰ì´ëŒ€ì¶œ', 1], # í‹°ì»¤ êµì²´ (TOTLL -> BUSLOANS)
        # ê±°ì‹œê²½ì œ
        'CPIAUCSL': ['MACRO', 'Inflation', 'CPI', 1],
        'PPIACO': ['MACRO', 'Inflation', 'PPI', 1],
        'PCEPI': ['MACRO', 'Inflation', 'PCEë¬¼ê°€', 1],
        'UNRATE': ['MACRO', 'Labor', 'ì‹¤ì—…ë¥ ', 1],
        'GDPC1': ['MACRO', 'Economy', 'ì‹¤ì§ˆGDP', 1],
        'RSXFS': ['MACRO', 'Economy', 'ì†Œë§¤íŒë§¤', 1],
        'DGORDER': ['MACRO', 'Economy', 'ë‚´êµ¬ì¬ì£¼ë¬¸', 1],
        'DEXKOUS': ['MACRO', 'Currency', 'ì›ë‹¬ëŸ¬í™˜ìœ¨', 1]
    }

    for group_name, sheet_id in sheets_info.items():
        if not sheet_id: continue
        try:
            sheet = client.open_by_key(sheet_id).sheet1
            new_rows = []

            # A. yfinance ë°ì´í„° (ìì‚° ê°€ê²©)
            group_yf = {k: v for k, v in yf_map.items() if v[0] == group_name}
            for ticker, info in group_yf.items():
                print(f"Fetching {info[2]}...")
                df = yf.download(ticker, start=start_date, progress=False)
                if not df.empty:
                    # ìµœì‹  pandas ë²„ì „ì˜ MultiIndex ëŒ€ì‘
                    close_series = df['Close'][ticker] if isinstance(df['Close'], pd.DataFrame) else df['Close']
                    for date, val in close_series.tail(500).items(): # ìµœê·¼ 500ì¼ì¹˜ ì§‘ì¤‘ ë³´ê°•
                        if pd.notna(val):
                            new_rows.append([date.strftime('%Y-%m-%d'), info[1], info[2], round(float(val), 2)])

            # B. FRED ë°ì´í„° (ë§¤í¬ë¡œ ì§€í‘œ)
            group_fred = {k: v for k, v in fred_map.items() if v[0] == group_name}
            for ticker, info in group_fred.items():
                print(f"Fetching {info[2]}...")
                try:
                    s = fred.get_series(ticker, observation_start=start_date)
                    for date, val in s.items():
                        if pd.notna(val) and val != ".":
                            new_rows.append([date.strftime('%Y-%m-%d'), info[1], info[2], round(float(val)/info[3], 3)])
                except: continue

            # 3. ë°ì´í„° ì •ì œ: ì¤‘ë³µ ì œê±° ë° ë¬´ê²°ì„± í™•ë³´
            if new_rows:
                final_df = pd.DataFrame(new_rows, columns=["Date", "Category", "Name", "Value"])
                # ë‚ ì§œì™€ ì´ë¦„ì´ ê°™ì€ ì¤‘ë³µ ë°ì´í„° ì¤‘ ìµœì‹ ê°’ë§Œ ë‚¨ê¹€
                final_df = final_df.drop_duplicates(subset=["Date", "Name"], keep='last')
                final_df = final_df.sort_values(by=["Date", "Name"])
                
                sheet.clear()
                sheet.append_row(["Date", "Category", "Name", "Value"])
                sheet.append_rows(final_df.values.tolist())
                print(f"âœ… {group_name} Update Success.")
            
            time.sleep(1) # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
        except Exception as e:
            print(f"ğŸš¨ {group_name} Error: {e}")

if __name__ == "__main__":
    daily_professional_update()
